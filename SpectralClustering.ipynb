{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing\n",
    "This cell is only concerned with importing the libraries and methods needed for implementing spectral clustering."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading data\n",
    "To run the algorithm, we read the data in 2 multidimensional arrays, one for training of size 19*8*48*125*45, and one for evaluation of size 19*8*12*125*45."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "aps_eval = []\n",
    "temp = []\n",
    "for i in range(1, 20):\n",
    "    p_eval = []\n",
    "    for j in range(1, 9):\n",
    "        s_eval = []\n",
    "        for k in range (49, 61):\n",
    "            temp = []\n",
    "            path = \"data\\\\a\"\n",
    "            path += f'0{i}' if i < 10 else f'{i}'\n",
    "            path += f'\\\\p{j}\\\\s'\n",
    "            path += f'{k}.txt'\n",
    "            file = open(path, \"r\")\n",
    "            for l in range(125):\n",
    "                temp.append(np.array(file.readline().split(','), dtype=float))\n",
    "            s_eval.append(np.array(temp))\n",
    "        p_eval.append(np.array(np.array(s_eval)))\n",
    "    aps_eval.append(np.array(p_eval))\n",
    "aps_eval = np.array(aps_eval)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1824\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "eval_points_means = []\n",
    "for a in range(19):\n",
    "    for p in range(8):\n",
    "        for s in range(12):\n",
    "            eval_points_means.append(np.mean(aps_eval[a][p][s], axis=0))\n",
    "eval_points_means = np.array(eval_points_means)\n",
    "print(len(eval_points_means))\n",
    "print(len(eval_points_means[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1824\n",
      "136\n"
     ]
    }
   ],
   "source": [
    "eval_points_flattened = []\n",
    "for a in range(19):\n",
    "    for p in range(8):\n",
    "        for s in range(12):\n",
    "            eval_points_flattened.append([])\n",
    "            for r in range(125):\n",
    "                for n in range(45):\n",
    "                    eval_points_flattened[a*96+p*12+s].append(aps_eval[a][p][s][r][n])\n",
    "eval_points_flattened = PCA(n_components=0.85).fit_transform(eval_points_flattened)\n",
    "print(len(eval_points_flattened))\n",
    "print(len(eval_points_flattened[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "sim_mat_means = rbf_kernel(eval_points_means, eval_points_means, 0.00001)\n",
    "for i in range(len(sim_mat_means)):\n",
    "    x = np.sum(sim_mat_means[i]) - 1\n",
    "    sim_mat_means[i] /= -x\n",
    "    sim_mat_means[i][i] = 1.0\n",
    "\n",
    "sim_mat_flattened = rbf_kernel(eval_points_flattened, eval_points_flattened, 0.00001)\n",
    "for i in range(len(sim_mat_flattened)):\n",
    "    x = np.sum(sim_mat_flattened[i]) - 1\n",
    "    sim_mat_flattened[i] /= -x\n",
    "    sim_mat_flattened[i][i] = 1.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "eigen_values, eigen_vectors = np.linalg.eig(sim_mat_means)\n",
    "idx = np.real(eigen_values).argsort()[::-1]\n",
    "eigen_vectors = np.real(np.array(eigen_vectors[idx, :]).transpose())\n",
    "data_means = []\n",
    "for l, eigen_vector in zip(range(19), eigen_vectors):\n",
    "    if len(data_means) == 0:\n",
    "        data_means.append(eigen_vector)\n",
    "    else:\n",
    "        data_means = np.append(data_means, [eigen_vector], axis=0)\n",
    "data_means = np.array(data_means).transpose()\n",
    "\n",
    "eigen_values, eigen_vectors = np.linalg.eig(sim_mat_flattened)\n",
    "idx = np.real(eigen_values).argsort()[::-1]\n",
    "eigen_vectors = np.real(np.array(eigen_vectors[idx, :]).transpose())\n",
    "data_flattened = []\n",
    "for l, eigen_vector in zip(range(19), eigen_vectors):\n",
    "    if len(data_flattened) == 0:\n",
    "        data_flattened.append(eigen_vector)\n",
    "    else:\n",
    "        data_flattened = np.append(data_flattened, [eigen_vector], axis=0)\n",
    "data_flattened = np.array(data_flattened).transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "for i in range(len(data_means)):\n",
    "    vec_sum = np.linalg.norm(data_means[i])\n",
    "    data_means[i] /= vec_sum\n",
    "\n",
    "for i in range(len(data_flattened)):\n",
    "    vec_sum = np.linalg.norm(data_flattened[i])\n",
    "    data_flattened[i] /= vec_sum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20045943118572188\n",
      "0.26340144637892726\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=19)\n",
    "kmeans.fit(data_means)\n",
    "print(metrics.silhouette_score(data_means, kmeans.labels_))\n",
    "labels_file = open(\"labels.txt\", \"w\")\n",
    "for i in range(19):\n",
    "    for j in range(8):\n",
    "        for q in range(12):\n",
    "            labels_file.write(str(kmeans.labels_[i*96+j*12+q]))\n",
    "            labels_file.write(\" \")\n",
    "        labels_file.write('\\n')\n",
    "    labels_file.write('\\n')\n",
    "labels_file.close()\n",
    "kmeans = KMeans(n_clusters=19)\n",
    "kmeans.fit(data_flattened)\n",
    "print(metrics.silhouette_score(data_flattened, kmeans.labels_))\n",
    "labels_file = open(\"labels1.txt\", \"w\")\n",
    "for i in range(19):\n",
    "    for j in range(8):\n",
    "        for q in range(12):\n",
    "            labels_file.write(str(kmeans.labels_[i*96+j*12+q]))\n",
    "            labels_file.write(\" \")\n",
    "        labels_file.write('\\n')\n",
    "    labels_file.write('\\n')\n",
    "labels_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}